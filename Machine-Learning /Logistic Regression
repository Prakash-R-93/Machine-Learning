{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":478459,"sourceType":"datasetVersion","datasetId":222474}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prakashramsamy93/heart-disease-prediction-using-logistic-regression?scriptVersionId=232561508\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Introduction**","metadata":{}},{"cell_type":"markdown","source":"In this project, we will evaluate the Logisitic Regression Machine Learning model performance.\n\nWe will be using the famous Kaggle dataset \"Framingham Heart Study (FHS)\" for this study. This study intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression.","metadata":{}},{"cell_type":"markdown","source":"# **Importing necessary libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:41:59.577841Z","iopub.execute_input":"2025-04-08T04:41:59.578234Z","iopub.status.idle":"2025-04-08T04:42:00.478556Z","shell.execute_reply.started":"2025-04-08T04:41:59.578203Z","shell.execute_reply":"2025-04-08T04:42:00.477557Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Loading dataset**","metadata":{}},{"cell_type":"code","source":"#loading dataset\ndf=pd.read_csv('/kaggle/input/logistic-regression-heart-disease-prediction/framingham_heart_disease.csv')\n\n#Display the first few rows\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:05.45893Z","iopub.execute_input":"2025-04-08T04:42:05.459381Z","iopub.status.idle":"2025-04-08T04:42:05.493454Z","shell.execute_reply.started":"2025-04-08T04:42:05.459354Z","shell.execute_reply":"2025-04-08T04:42:05.492643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Display the columns\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:09.606825Z","iopub.execute_input":"2025-04-08T04:42:09.607201Z","iopub.status.idle":"2025-04-08T04:42:09.613324Z","shell.execute_reply.started":"2025-04-08T04:42:09.607173Z","shell.execute_reply":"2025-04-08T04:42:09.612226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:12.350556Z","iopub.execute_input":"2025-04-08T04:42:12.350929Z","iopub.status.idle":"2025-04-08T04:42:12.35662Z","shell.execute_reply.started":"2025-04-08T04:42:12.350872Z","shell.execute_reply":"2025-04-08T04:42:12.355563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data cleaning and Transformation**","metadata":{}},{"cell_type":"markdown","source":"Handling missing values:","metadata":{}},{"cell_type":"code","source":"#Checking for missing values\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:14.949669Z","iopub.execute_input":"2025-04-08T04:42:14.950082Z","iopub.status.idle":"2025-04-08T04:42:14.959461Z","shell.execute_reply.started":"2025-04-08T04:42:14.950049Z","shell.execute_reply":"2025-04-08T04:42:14.958555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Since education having more missing values & it contributes less, lets drop the column\ndf=df.drop(['education'], axis=1)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:18.050395Z","iopub.execute_input":"2025-04-08T04:42:18.050802Z","iopub.status.idle":"2025-04-08T04:42:18.070223Z","shell.execute_reply.started":"2025-04-08T04:42:18.050767Z","shell.execute_reply":"2025-04-08T04:42:18.068877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets find out the mean values for replacing with missing values\ncigsPerDay_mean = round(df[\"cigsPerDay\"].mean())\nBPMeds_mean = round(df[\"BPMeds\"].mean())\ntotChol_mean = round(df[\"totChol\"].mean())\nBMI_mean = round(df[\"BMI\"].mean())\nheartRate_mean = round(df[\"heartRate\"].mean())\nglucose_mean = round(df[\"glucose\"].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:21.803908Z","iopub.execute_input":"2025-04-08T04:42:21.804317Z","iopub.status.idle":"2025-04-08T04:42:21.812474Z","shell.execute_reply.started":"2025-04-08T04:42:21.804289Z","shell.execute_reply":"2025-04-08T04:42:21.811444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Replace the missing values with mean values\ndf['cigsPerDay'].fillna(cigsPerDay_mean, inplace = True)\ndf['BPMeds'].fillna(BPMeds_mean, inplace = True)\ndf['totChol'].fillna(totChol_mean, inplace = True)\ndf['BMI'].fillna(BMI_mean, inplace = True)\ndf['heartRate'].fillna(heartRate_mean, inplace = True)\ndf['glucose'].fillna(glucose_mean, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:24.377581Z","iopub.execute_input":"2025-04-08T04:42:24.377974Z","iopub.status.idle":"2025-04-08T04:42:24.386283Z","shell.execute_reply.started":"2025-04-08T04:42:24.37793Z","shell.execute_reply":"2025-04-08T04:42:24.385244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking for missing values\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:27.073766Z","iopub.execute_input":"2025-04-08T04:42:27.074128Z","iopub.status.idle":"2025-04-08T04:42:27.08188Z","shell.execute_reply.started":"2025-04-08T04:42:27.074098Z","shell.execute_reply":"2025-04-08T04:42:27.080955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Creating a pair wise plot for each columns\nsns.pairplot(df[[\"age\",\"cigsPerDay\",\"totChol\", \"sysBP\",\"diaBP\", \"BMI\", \"heartRate\", \"glucose\"]]);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:42:30.663893Z","iopub.execute_input":"2025-04-08T04:42:30.664287Z","iopub.status.idle":"2025-04-08T04:42:50.125549Z","shell.execute_reply.started":"2025-04-08T04:42:30.664258Z","shell.execute_reply":"2025-04-08T04:42:50.124448Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Splitting the dataset**","metadata":{}},{"cell_type":"code","source":"# Splitting the DataFrame into predictor variables and target variable\n\nX = df.drop('TenYearCHD',axis=1)\n\n# Load the target variable to y\n\ny=df['TenYearCHD']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:15.419525Z","iopub.execute_input":"2025-04-08T04:43:15.419858Z","iopub.status.idle":"2025-04-08T04:43:15.425811Z","shell.execute_reply.started":"2025-04-08T04:43:15.41983Z","shell.execute_reply":"2025-04-08T04:43:15.424857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train/Test splitting of data \n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)\n\nprint(X.shape, X_train.shape, X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:18.437026Z","iopub.execute_input":"2025-04-08T04:43:18.43734Z","iopub.status.idle":"2025-04-08T04:43:18.513831Z","shell.execute_reply.started":"2025-04-08T04:43:18.437316Z","shell.execute_reply":"2025-04-08T04:43:18.512998Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model creation**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nClassifier = LogisticRegression()\n\n# Train the Logistic Regression Model\n\nClassifier.fit(X_train,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:21.328945Z","iopub.execute_input":"2025-04-08T04:43:21.329388Z","iopub.status.idle":"2025-04-08T04:43:21.414723Z","shell.execute_reply.started":"2025-04-08T04:43:21.329356Z","shell.execute_reply":"2025-04-08T04:43:21.413875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model evaluation**","metadata":{}},{"cell_type":"code","source":"#Finding the accuracy of the model\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:25.420839Z","iopub.execute_input":"2025-04-08T04:43:25.421238Z","iopub.status.idle":"2025-04-08T04:43:25.425694Z","shell.execute_reply.started":"2025-04-08T04:43:25.421207Z","shell.execute_reply":"2025-04-08T04:43:25.42448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# accuracy on training data\nX_train_prediction = Classifier.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_prediction, y_train)\n\nprint('Accuracy on Training data : ', training_data_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:27.738358Z","iopub.execute_input":"2025-04-08T04:43:27.738709Z","iopub.status.idle":"2025-04-08T04:43:27.747978Z","shell.execute_reply.started":"2025-04-08T04:43:27.738681Z","shell.execute_reply":"2025-04-08T04:43:27.747018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# accuracy on test data\nX_test_prediction = Classifier.predict(X_test)\ntest_data_accuracy = accuracy_score(X_test_prediction, y_test)\n\nprint('Accuracy on Test data : ', test_data_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:30.477891Z","iopub.execute_input":"2025-04-08T04:43:30.478247Z","iopub.status.idle":"2025-04-08T04:43:30.487221Z","shell.execute_reply.started":"2025-04-08T04:43:30.478223Z","shell.execute_reply":"2025-04-08T04:43:30.486212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets print the classification report\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, X_test_prediction))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:32.780807Z","iopub.execute_input":"2025-04-08T04:43:32.78124Z","iopub.status.idle":"2025-04-08T04:43:32.79526Z","shell.execute_reply.started":"2025-04-08T04:43:32.781207Z","shell.execute_reply":"2025-04-08T04:43:32.794187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\ncm=confusion_matrix(y_test,X_test_prediction)\n\nprint(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:43:35.488002Z","iopub.execute_input":"2025-04-08T04:43:35.488354Z","iopub.status.idle":"2025-04-08T04:43:35.495964Z","shell.execute_reply.started":"2025-04-08T04:43:35.488326Z","shell.execute_reply":"2025-04-08T04:43:35.495075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"With this, we have done basic EDA on the dataset, splitted the dataset into training & test parameters, created a Logistic Regression model, evaluated the model performance with basic evaluation metrics like Classification report & confusion matrix.","metadata":{}},{"cell_type":"markdown","source":"Thank you!","metadata":{}}]}